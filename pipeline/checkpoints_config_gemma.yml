# StarCoder2-7B LoRA Checkpoints Configuration
# This file defines the paths to different LoRA checkpoint directories

checkpoints:
  annotated:
    path: "/mnt/teamssd/compressed_LLM_tbricks/finetune_gemma_2b_annotation_merged_attentionlayeronly/checkpoint-40000"
    description: "Annotated training data checkpoint"
    
  multiline:
    path: "/mnt/teamssd/compressed_LLM_tbricks/finetune_gemma_2b_multi_merged_attentionlayeronly/checkpoint-40000"
    description: "Multiline training data checkpoint"
    
  singleline:
    path: "/mnt/teamssd/compressed_LLM_tbricks/finetune_gemma_2b_single_merged_attentionlayeronly/checkpoint-40000"
    description: "Singleline training data checkpoint"
    
  concatenationTrained:
    path: "/mnt/teamssd/compressed_LLM_tbricks/finetune_gemma_2b_triple_merged_attentionlayeronly/checkpoint-40000"
    description: "Concatenation trained checkpoint (target for optimization)"

# Optional settings
settings:
  # Verify that all checkpoints exist before processing
  verify_paths: true
  
  # Show detailed path information during processing
  verbose_paths: true
  
  # Additional checkpoints can be added here as needed
  # custom_checkpoint:
  #   path: "/path/to/custom/checkpoint"
  #   description: "Custom checkpoint description"
